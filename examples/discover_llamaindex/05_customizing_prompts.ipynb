{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I am assuming you have the relevant API_KEYs as environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "import os\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANIES = [\"uber\"]\n",
    "DATA_DIRS = {}\n",
    "PERSIST_DIRS = {}\n",
    "for c in COMPANIES:\n",
    "    DATA_DIRS[c] = os.path.join(os.environ[\"DATA_DIR\"], f\"{c}\")\n",
    "    PERSIST_DIRS[c] = os.path.join(os.environ[\"PERSIST_DIR\"], f\"{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "You can access more files by usinig the next url format\n",
    "\n",
    "https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/{`COMPANY_NAME`}_10q_{`MONTH`}_{`YEAR`}.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in COMPANIES:\n",
    "    if not os.path.exists(DATA_DIRS[c]):\n",
    "        os.mkdir(DATA_DIRS[c])\n",
    "        command = f\"wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/{c}_2021.pdf' -O '{DATA_DIRS[c]}/{c}_2021.pdf'\"        \n",
    "        subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create index and query engine for each company individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Index\n"
     ]
    }
   ],
   "source": [
    "query_engine_dict = {}\n",
    "for c in COMPANIES:\n",
    "    if not os.path.exists(PERSIST_DIRS[c]):\n",
    "        print(\"Creating Index\")\n",
    "        # load the documents and create the index\n",
    "        documents = SimpleDirectoryReader(DATA_DIRS[c]).load_data()\n",
    "        index = VectorStoreIndex.from_documents(documents)\n",
    "        # store it for later\n",
    "        index.storage_context.persist(persist_dir=PERSIST_DIRS[c])\n",
    "    else:\n",
    "        print(\"Loading Index\")\n",
    "        # load the existing index\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIRS[c])\n",
    "        index = load_index_from_storage(storage_context)\n",
    "    \n",
    "    query_engine_dict[c] = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prompt viewing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Accessing Prompts\n",
    "\n",
    "Here we get the prompts from the query engine. Note that all prompts are returned, including ones used in sub-modules in the query engine. This allows you to centralize a view of these prompts!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = query_engine_dict[\"uber\"].get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue changed from $11,139 million in 2019 to $17,455 million in 2021, representing a 57% increase from 2020 to 2021.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_dict[\"uber\"].query(\"How has total revenue changed in 2019, 2020 and 2021?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Customize the prompt\n",
    "\n",
    "You can also update/customize the prompts with the update_prompts function. Pass in arg values with the keys equal to the keys you see in the prompt dictionary.\n",
    "\n",
    "Here we'll change the text_qa_template to generate response in both english and Spanish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmpl_str = (\n",
    "        \"Below is the specific context required to answer the upcoming query. You must base your response solely on this context, strictly avoiding the use of external knowledge or assumptions..\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context_str}\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"Given this context, please formulate your response to the following query. It is imperative that you respond in Spanish and English.\\n\"\n",
    "        \"Query: {query_str}\\n\"\n",
    "        \"Answer: \"\n",
    "    )\n",
    "new_tmpl = PromptTemplate(new_tmpl_str)\n",
    "query_engine_dict[\"uber\"].update_prompts({\"response_synthesizer:text_qa_template\": new_tmpl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the specific context required to answer the upcoming query. You must base your response solely on this context, strictly avoiding the use of external knowledge or assumptions..\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given this context, please formulate your response to the following query. It is imperative that you respond in Spanish and English.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = query_engine_dict[\"uber\"].get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue has changed as follows:\n",
      "- In 2019, the revenue was not provided in the context.\n",
      "- In 2020, the revenue was $11,139 million.\n",
      "- In 2021, the revenue increased to $17,455 million, representing a 57% increase compared to 2020. \n",
      "\n",
      "El total de ingresos ha cambiado de la siguiente manera:\n",
      "- En 2019, los ingresos no se proporcionaron en el contexto.\n",
      "- En 2020, los ingresos fueron de $11,139 millones.\n",
      "- En 2021, los ingresos aumentaron a $17,455 millones, lo que representa un aumento del 57% en comparaci√≥n con 2020.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_dict[\"uber\"].query(\"How has total revenue changed in 2019, 2020 and 2021?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
