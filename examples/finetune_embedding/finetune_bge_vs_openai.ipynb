{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inpired by [this LlamaIndex example](https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding/)\n",
    "\n",
    "Making some changes to it with the only intention of trying ideas and learning.\n",
    "\n",
    "Notice that I am assuming you have the relevant API_KEYs as environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-finetuning\n",
    "%pip install llama-index-embeddings-openai\n",
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bubls.utils.data.download import download_file_from_url\n",
    "from bubls.utils.data.loading import load_corpus\n",
    "from bubls.utils.evaluation.evaluate_embeddings import (\n",
    "    get_query_hit_pairs, sentence_transformer_ir_evaluator\n",
    ")\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA = {\n",
    "    \"train\": {\n",
    "        \"lyft_10k\": {\n",
    "            \"source_url\": \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\",\n",
    "            \"file_name\": \"lyft_10k_2021.pdf\",\n",
    "            \"save_data_to\": os.path.join(os.environ[\"DATA_DIR\"], \"lyft_10k\"),\n",
    "        }\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"uber_10k\": {\n",
    "            \"source_url\": \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\",\n",
    "            \"file_name\": \"uber_10k_2021.pdf\",\n",
    "            \"save_data_to\": os.path.join(os.environ[\"DATA_DIR\"], \"uber_10k\"),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "PERSIST_FINETUNE_DATA_TO = os.path.join(os.environ[\"PERSIST_DIR\"], \"eg1_finetune_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data\n",
    "- Download Information\n",
    "- Split train and validation data\n",
    "- Load corpus\n",
    "- Generate QA embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with QA embedding pairs\n",
      "Loading data with QA embedding pairs\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for split in METADATA:\n",
    "    files = []\n",
    "    for k, md in METADATA[split].items():\n",
    "        files.append(\n",
    "            download_file_from_url(md[\"source_url\"], md[\"file_name\"], md[\"save_data_to\"])\n",
    "        )\n",
    "    data_path = os.path.join(PERSIST_FINETUNE_DATA_TO, f\"{split}_data.json\")\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Generating data with QA embedding pairs\")\n",
    "        # For every node we have id, embedding placeholder, metadata, text, relationships, etc.\n",
    "        nodes = load_corpus(files, verbose=True)\n",
    "        data[split] = generate_qa_embedding_pairs(\n",
    "            llm=OpenAI(model=\"gpt-3.5-turbo\"), nodes=nodes\n",
    "        )\n",
    "        data[split].save_json(data_path)\n",
    "    else:\n",
    "        print(\"Loading data with QA embedding pairs\")\n",
    "        data[split] = EmbeddingQAFinetuneDataset.from_json(data_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Embedding Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    data[\"train\"],\n",
    "    model_id=\"BAAI/bge-small-en\",\n",
    "    model_output_path=\"finetuned_model\",\n",
    "    val_dataset=data[\"val\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block of code executes the training and returns the model \n",
    "## I am currently running this in a RPi5 so unfortunately can't execute it locally.\n",
    "# finetune_engine.finetune()\n",
    "# embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and compare\n",
    "I am going to evaluate the performance of `BAAI/bge-small-en` vs `OpenAI`.\n",
    "I couldn't include the fine-tuned one because I couldn't execute it because of memory constraints. NEvertheless all the ideas hold and the process would be the same as what you will find next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8829268292682927"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_embedding = OpenAIEmbedding()\n",
    "ada_val_results = get_query_hit_pairs(data[\"val\"], openai_embedding)\n",
    "df_ada = pd.DataFrame(ada_val_results)\n",
    "hit_rate_ada = df_ada[\"is_hit\"].mean()\n",
    "hit_rate_ada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAAI/bge-small-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802439024390244"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bge = \"local:BAAI/bge-small-en\"\n",
    "bge_val_results = get_query_hit_pairs(data[\"val\"], bge)\n",
    "df_bge = pd.DataFrame(bge_val_results)\n",
    "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
    "hit_rate_bge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_val_results = sentence_transformer_ir_evaluator(data[\"val\"], bge, \"bge\")\n",
    "df_bge = pd.DataFrame(bge_val_results)\n",
    "df_bge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuned\n",
    "Fine-tuning our small open-source embedding model drastically improved its retrieval quality, comparable to the quality of the OpenAI embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = \"local:finetuned_model\"\n",
    "ada_val_results = get_query_hit_pairs(data[\"val\"], finetuned)\n",
    "df_ada = pd.DataFrame(ada_val_results)\n",
    "hit_rate_ada = df_ada[\"is_hit\"].mean()\n",
    "hit_rate_ada\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
