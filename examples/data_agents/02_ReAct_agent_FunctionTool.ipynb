{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inpired by [this LlamaIndex notebook](https://colab.research.google.com/drive/1XYNaGvEdyKVbs4g_Maffyq08DUArcW8H?usp=sharing#scrollTo=fQW2ccGlLrg7)\n",
    "\n",
    "I edited the original notebook to focus on Open AI LLMs, I am focusing on comparing **gpt-3.5-turbo** vs. **gpt-4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I am assuming you have the relevant API_KEYs as environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bubls.utils.agents.general_function_tools import (\n",
    "    multiply_tool,\n",
    "    add_tool,\n",
    "    subtract_tool\n",
    ")\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply_tool, add_tool, subtract_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI\n",
    "### GPT 3.5-turbo vs GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt3 = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "gpt3_agent = ReActAgent.from_tools(tools, llm=llm_gpt3, verbose=True)\n",
    "\n",
    "llm_gpt4 = OpenAI(model=\"gpt-4\")\n",
    "gpt4_agent = ReActAgent.from_tools(tools, llm=llm_gpt4, verbose=True)\n",
    "\n",
    "# agent without multiply_tool\n",
    "gpt4_agent_incomplete = ReActAgent.from_tools([add_tool, subtract_tool], llm=llm_gpt4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 8\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 20 + (2 * 4) = 20 + 8 = 28\n",
      "\u001b[0m---\n",
      " Response\n",
      " 20 + (2 * 4) = 20 + 8 = 28\n"
     ]
    }
   ],
   "source": [
    "response = gpt3_agent.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The user wants to calculate the expression 20+(2*4) step by step. The first step is to perform the multiplication operation, which is 2*4.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 8\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The result of the multiplication operation 2*4 is 8. Now, I need to add this result to 20 to get the final answer.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. The result of the addition operation 20+8 is 28, which is the final answer to the expression 20+(2*4).\n",
      "Answer: The result of the expression 20+(2*4) is 28.\n",
      "\u001b[0m---\n",
      " Response\n",
      " The result of the expression 20+(2*4) is 28.\n"
     ]
    }
   ],
   "source": [
    "response = gpt4_agent.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question. The first step is to calculate the multiplication part of the equation, which is 2*4.\n",
      "Action: add\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 6\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The tool seems to have made a mistake. The multiplication of 2 and 4 should be 8, not 6. I'll correct this and proceed to the next step, which is adding 20 to the result of the multiplication.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The result of the calculation 20+(2*4) is 28.\n",
      "\u001b[0m---\n",
      " Response\n",
      " The result of the calculation 20+(2*4) is 28.\n"
     ]
    }
   ],
   "source": [
    "response = gpt4_agent_incomplete.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic and Mistral AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.mistralai import MistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_llm = Anthropic(model=\"claude-3-sonnet-20240229\")\n",
    "anthropic_agent = ReActAgent.from_tools([multiply_tool, add_tool, subtract_tool], llm=anthropic_llm, verbose=True)\n",
    "response = anthropic_agent.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralai_llm = MistralAI(model=\"mistral-large-latest\")\n",
    "mistralai_agent = ReActAgent.from_tools([multiply_tool, add_tool, subtract_tool], llm=mistralai_llm, verbose=True)\n",
    "response = mistralai_agent.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
