{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inpired by [this LlamaIndex notebook](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/agent/coa_agent.ipynb)\n",
    "\n",
    "[Original Chain-of-Abstraction paper](https://arxiv.org/abs/2401.17464)\n",
    "\n",
    "Making some changes to it with the only intention of trying ideas and learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I am assuming you have the relevant API_KEYs as environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-packs-agents-coa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bubls.utils.data.download import download_file_from_url\n",
    "from bubls.utils.indexing import create_index_from_path\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.packs.agents_coa import CoAAgentWorker\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\", embed_batch_size=256\n",
    ")\n",
    "Settings.llm = OpenAI(model=\"gpt-4-turbo\", temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA = {\n",
    "    \"lyft_10k\": {\n",
    "        \"source_url\": \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\",\n",
    "        \"file_name\": \"lyft_10k_2021.pdf\",\n",
    "        \"save_data_to\": os.path.join(os.environ[\"DATA_DIR\"], \"lyft_10k\"),\n",
    "        \"persist_index_to\": os.path.join(os.environ[\"PERSIST_DIR\"], \"lyft_10k\"),\n",
    "        },\n",
    "    \"uber_10k\": {\n",
    "        \"source_url\": \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\",\n",
    "        \"file_name\": \"uber_10k_2021.pdf\",\n",
    "        \"save_data_to\": os.path.join(os.environ[\"DATA_DIR\"], \"uber_10k\"),\n",
    "        \"persist_index_to\": os.path.join(os.environ[\"PERSIST_DIR\"], \"uber_10k\"),\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data\n",
    "- Download Information\n",
    "- Create&Persist or Load Index \n",
    "- Create Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = LlamaParse(result_type=\"markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Index\n",
      "Loading Index\n"
     ]
    }
   ],
   "source": [
    "query_engine_dict = {}\n",
    "for k, md in METADATA.items():\n",
    "    download_file_from_url(md[\"source_url\"], md[\"file_name\"], md[\"save_data_to\"])\n",
    "    index = create_index_from_path(\n",
    "        md[\"persist_index_to\"],\n",
    "        md[\"save_data_to\"],\n",
    "        # {\".pdf\": parser}\n",
    "    )\n",
    "    query_engine_dict[k] = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine_dict[k],\n",
    "        metadata=ToolMetadata(\n",
    "            name=k,\n",
    "            description=(\n",
    "                f\"Provides information about {k} financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    for k in METADATA.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "- The tools get parsed into python-like definitions\n",
    "- The agent is prompted to generate a CoA plan\n",
    "- The function calls are parsed out of the plan and executed\n",
    "- The values in the plan are filled in\n",
    "- The agent generates a final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Available Parsed Functions ====\n",
      "def lyft_10k(input: string):\n",
      "   \"\"\"Provides information about lyft_10k financials for year 2021. Use a detailed plain text question as input to the tool.\"\"\"\n",
      "    ...\n",
      "def uber_10k(input: string):\n",
      "   \"\"\"Provides information about uber_10k financials for year 2021. Use a detailed plain text question as input to the tool.\"\"\"\n",
      "    ...\n",
      "==== Generated Chain of Abstraction ====\n",
      "Abstract plan of reasoning:\n",
      "1. Retrieve Uber's revenue for 2021 by querying the Uber financial tool with a specific question about revenue. This can be done using the function call [FUNC uber_10k(\"What was Uber's revenue in 2021?\") = y1].\n",
      "2. Retrieve Lyft's revenue for 2021 by querying the Lyft financial tool with a similar question about revenue. This can be done using the function call [FUNC lyft_10k(\"What was Lyft's revenue in 2021?\") = y2].\n",
      "3. Compare the revenue figures obtained from Uber and Lyft to determine which company had greater revenue growth. This comparison will be based on the values obtained from y1 and y2, and the final response will discuss whether Uber's revenue growth (y1) was higher, lower, or equal to Lyft's revenue growth (y2).\n",
      "==== Executing uber_10k with inputs [\"What was Uber's revenue in 2021?\"] ====\n",
      "==== Executing lyft_10k with inputs [\"What was Lyft's revenue in 2021?\"] ====\n"
     ]
    }
   ],
   "source": [
    "worker = CoAAgentWorker.from_tools(\n",
    "    tools=query_engine_tools,\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    ")\n",
    "agent = AgentRunner(worker)\n",
    "response = agent.chat(\"How did Ubers revenue growth compare to Lyfts in 2021?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context information does not include specific details about the revenue figures for Uber and Lyft in 2021. Therefore, I am unable to determine how Uber's revenue growth compared to Lyft's in that year.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the prompting of Chain of Abstraction works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this actually work?\n",
    "\n",
    "So, under the hood we are prompting the LLM to first output the CoA, then we parse it and run functions, then we refine all that into a final output.\n",
    "\n",
    "First, we parse the tools into python-like function defintions by parsing `tool.metadata.fn_schema_str`, along with the tool name and description.\n",
    "\n",
    "You can find that code in the [utils](https://notebooks.githubusercontent.com/view/ipynb?browser=firefox&bypass_fastly=true&color_mode=auto&commit=7b52057b717451a801c583fae7efe4c4ad167455&device=unknown_device&docs_host=https%3A%2F%2Fdocs.github.com&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72756e2d6c6c616d612f6c6c616d615f696e6465782f376235323035376237313734353161383031633538336661653765666534633461643136373435352f646f63732f646f63732f6578616d706c65732f6167656e742f636f615f6167656e742e6970796e62&logged_in=true&nwo=run-llama%2Fllama_index&path=docs%2Fdocs%2Fexamples%2Fagent%2Fcoa_agent.ipynb&platform=linux&repository_id=560704231&repository_type=Repository&version=125).\n",
    "\n",
    "What this looks like is we have a prompt like this:\n",
    "\n",
    "REASONING_PROMPT_TEMPALTE = \"\"\"Generate an abstract plan of reasoning using placeholders for the specific values and function calls needed.\n",
    "The placeholders should be labeled y1, y2, etc.\n",
    "Function calls should be represented as inline strings like [FUNC {{function_name}}({{input1}}, {{input2}}, ...) = {{output_placeholder}}].\n",
    "Assume someone will read the plan after the functions have been executed in order to make a final response.\n",
    "Not every question will require function calls to answer.\n",
    "If you do invoke a function, only use the available functions, do not make up functions.\n",
    "\n",
    "Example:\n",
    "-----------\n",
    "Available functions:\n",
    "\\`\\`\\`python\n",
    "def add(a: int, b: int) -> int:\n",
    "    \\\"\\\"\\\"Add two numbers together.\\\"\\\"\\\"\n",
    "    ...\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \\\"\\\"\\\"Multiply two numbers together.\\\"\\\"\\\"\n",
    "    ...\n",
    "\\`\\`\\`\n",
    "\n",
    "Question:\n",
    "Sally has 3 apples and buys 2 more. Then magically, a wizard casts a spell that multiplies the number of apples by 3. How many apples does Sally have now?\n",
    "\n",
    "Abstract plan of reasoning:\n",
    "After buying the apples, Sally has [FUNC add(3, 2) = y1] apples. Then, the wizard casts a spell to multiply the number of apples by 3, resulting in [FUNC multiply(y1, 3) = y2] apples.\n",
    "\n",
    "Your Turn:\n",
    "-----------\n",
    "Available functions:\n",
    "\\`\\`\\`python\n",
    "{functions}\n",
    "\\`\\`\\`\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Abstract plan of reasoning:\n",
    "\"\"\"\n",
    "\n",
    "This will generate the chain-of-abstraction reasoning.\n",
    "\n",
    "Then, the reasoning is parsed using the [output parser](https://notebooks.githubusercontent.com/view/ipynb?browser=firefox&bypass_fastly=true&color_mode=auto&commit=7b52057b717451a801c583fae7efe4c4ad167455&device=unknown_device&docs_host=https%3A%2F%2Fdocs.github.com&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72756e2d6c6c616d612f6c6c616d615f696e6465782f376235323035376237313734353161383031633538336661653765666534633461643136373435352f646f63732f646f63732f6578616d706c65732f6167656e742f636f615f6167656e742e6970796e62&logged_in=true&nwo=run-llama%2Fllama_index&path=docs%2Fdocs%2Fexamples%2Fagent%2Fcoa_agent.ipynb&platform=linux&repository_id=560704231&repository_type=Repository&version=125).\n",
    "\n",
    "After calling the functions and filling in values, we give the LLM a chance to refine the response, using this prompt:\n",
    "\n",
    "REFINE_REASONING_PROMPT_TEMPALTE = \"\"\"Generate a response to a question by using a previous abstract plan of reasoning. Use the previous reasoning as context to write a response to the question.\n",
    "\n",
    "Example:\n",
    "-----------\n",
    "Question: \n",
    "Sally has 3 apples and buys 2 more. Then magically, a wizard casts a spell that multiplies the number of apples by 3. How many apples does Sally have now?\n",
    "\n",
    "Previous reasoning:\n",
    "After buying the apples, Sally has [FUNC add(3, 2) = 5] apples. Then, the wizard casts a spell to multiply the number of apples by 3, resulting in [FUNC multiply(5, 3) = 15] apples.\n",
    "\n",
    "Response:\n",
    "After the wizard casts the spell, Sally has 15 apples.\n",
    "\n",
    "Your Turn:\n",
    "-----------\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Previous reasoning:\n",
    "{prev_reasoning}\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
