{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inpired by [this LlamaIndex notebook](https://colab.research.google.com/drive/1R41zIhVybCNqg67eVEPuyLeMp_HYwTlA?usp=sharing)\n",
    "\n",
    "Making some changes to it with the only intention of trying ideas and learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I am assuming you have the relevant API_KEYs as environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bubls.utils.agents.general_function_tools import (\n",
    "    multiply_tool,\n",
    "    add_tool,\n",
    "    subtract_tool\n",
    ")\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def useless(a: str) -> str:\n",
    "    \"\"\"Toy useless function.\"\"\"\n",
    "    pass\n",
    "\n",
    "useless_tools = [\n",
    "    FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\n",
    "    for idx in range(100)\n",
    "]\n",
    "\n",
    "tools = [multiply_tool] + [add_tool] + [subtract_tool] + useless_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Retrieval Augmented to reduce latency and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_index = ObjectIndex.from_objects(\n",
    "    tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "llm_gpt = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
      "=== Function Output ===\n",
      "8\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
      "=== Function Output ===\n",
      "28\n",
      "=== LLM Response ===\n",
      "The result of 20+(2*4) is 28.\n",
      "---\n",
      " Response\n",
      " assistant: The result of 20+(2*4) is 28.\n",
      "CPU times: user 212 ms, sys: 8.64 ms, total: 221 ms\n",
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpt_worker_with_ra = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    llm=llm_gpt,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False\n",
    ")\n",
    "gpt_agent = AgentRunner(gpt_worker_with_ra)\n",
    "response = gpt_agent.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
      "=== Function Output ===\n",
      "8\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
      "=== Function Output ===\n",
      "28\n",
      "=== LLM Response ===\n",
      "The result of the calculation 20+(2*4) is 28.\n",
      "---\n",
      " Response\n",
      " assistant: The result of the calculation 20+(2*4) is 28.\n",
      "CPU times: user 189 ms, sys: 3.79 ms, total: 193 ms\n",
      "Wall time: 6.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpt_worker_without_ra = FunctionCallingAgentWorker.from_tools(\n",
    "    all_tools,\n",
    "    llm=llm_gpt,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False\n",
    ")\n",
    "gpt_agent_2 = AgentRunner(gpt_worker_without_ra)\n",
    "response = gpt_agent_2.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(\"---\\n\", \"Response\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
